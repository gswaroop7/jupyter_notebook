{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5410d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MY_SPENDINGS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"statement.csv\",header=True,inferSchema=True).fillna(0)\n",
    "\n",
    "#change Date from string to_date, rename column names with special charaters\n",
    "#Note: MM is capital not mm(minutes)\n",
    "df=df.select(f.to_date(df.Date,'dd/MM/yy').alias(\"Date\"),\"Narration\",\\\n",
    "             f.col(\"`Withdrawal Amt.`\").alias(\"Withdrawal\"),\\\n",
    "            #f.col(\"`Chq./Ref.No.`\").alias(\"Ref_Number\"),\\\n",
    "             f.col(\"`Deposit Amt.`\").alias(\"Deposit\")\\\n",
    "             #,\"Closing Balance\"\\\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db97b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Case : Removal of specific data\n",
    "df = df.filter((df.Deposit != 30000) & (df.Withdrawal != 30000) & (df.Deposit != 144807))\n",
    "\n",
    "df.show(1)\n",
    "#Remove Interest if needed\n",
    "\n",
    "    #Interesting that only &(and) and |(or) works here for removing two different ... \\\n",
    "    #... entires, where one have 30000 in Withdrawal and a different one have 30000 in Deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba001a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "#Use Case : Monthly saving vs spending\n",
    "#Logic : Salary gets credited on the last working day, so we need to add last working day to \n",
    "        #... next month and then groupby and sum the Income and Expenditure\n",
    "\n",
    "#calendar.monthcalendar takes year and month as input. [-1] to reverse month lists and [0] pick last one\n",
    "last_day = f.udf(lambda x,y: max(calendar.monthcalendar(int(x),int(y))[-1:][0][:5]))\n",
    "\n",
    "df = df.withColumn(\"Last_Workingday\",last_day((f.date_format(df.Date,'yyyy')),\\\n",
    "                                                 (f.date_format(df.Date,'MM'))))\n",
    "\n",
    "#Or you can use split to get the same output\n",
    "#dfs = dfs.withColumn(\"Last_Workingday\",last_day((f.split(f.col(\"Date\"),\"-\")[0]),\\\n",
    "#                                                (f.split(f.col(\"Date\"),\"-\")[1])))\n",
    "\n",
    "\n",
    "#Adding column that shall group based on the last working day\n",
    "#sometimes lastworking day could be holiday, so we need to check the \"SALARY\" credited date\n",
    "df = df.withColumn(\"year_month\",\\\n",
    "                 f.when((f.date_format(df.Date,'dd') < df.Last_Workingday) & \\\n",
    "                        (~df.Narration.contains(\"SALARY\")) ,f.date_format(df.Date,\"yyyy-MM\")).\\\n",
    "                 otherwise( f.date_format(f.date_add(df.Date,5),\"yyyy-MM\") ))\n",
    "\n",
    "#Spending\n",
    "expenditure = df.select(\"Deposit\",f.round(f.col(\"Withdrawal\")).alias(\"Withdrawal\"),\\\n",
    "                        \"year_month\").\\\n",
    "                    groupBy(\"year_month\").sum()\n",
    "\n",
    "#Savings\n",
    "savings = expenditure.withColumn(\"savings\",f.round(f.col(\"sum(Deposit)\")-f.col(\"sum(Withdrawal)\"))).\\\n",
    "                                                                                    sort(\"year_month\")\n",
    "savings = savings.select(\"year_month\",f.col(\"sum(Deposit)\").alias(\"Income\"),\\\n",
    "                         f.col(\"sum(Withdrawal)\").alias(\"Expenditure\"),\"savings\")\n",
    "\n",
    "sum_array = savings.groupBy().sum().select(\"*\",f.col(\"sum(savings)\").alias(\"Total_Savings\"))\\\n",
    "                                    .drop(\"sum(savings)\")\n",
    "avg_array = savings.groupBy().avg().select(\"*\",f.round(f.col(\"avg(Expenditure)\")).alias(\"Avg Monthly Expenditure\"))\\\n",
    "                                    .drop(\"avg(Expenditure)\")\n",
    "\n",
    "for item in avg_array.collect():    #collect gives you row wise output and each row converts to dictonary\n",
    "    avg_dict = item.asDict()\n",
    "    \n",
    "for item in sum_array.collect():\n",
    "    sum_dict = item.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8abd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pyspark DF to PandasDF(pdf) and then plot\n",
    "pdf = savings.toPandas()\n",
    "\n",
    "import plotly                             #### You need to have pandas installed\n",
    "import plotly.express as px               #to create interactive charts\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(f\"You saved {sum_dict['Total_Savings']} Rupees, till now\")\n",
    "print(f\"You are spending an average of {avg_dict['Avg Monthly Expenditure']} Rupees per month\")\n",
    "\n",
    "px.bar(pdf,x=\"year_month\",y=[pdf[\"Income\"],pdf[\"Expenditure\"],pdf[\"savings\"]],\\\n",
    "                        barmode=\"group\",title=\"Income vs Expenditure vs Savings\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6258b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learnings:\n",
    "    #fs = df1.filter(df1.Narration.contains(\"SALARY\"))\n",
    "    #f.udf  #have to regularly check "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
